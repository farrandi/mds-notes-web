<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>MDS cheatsheets – sup_learn</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">MDS cheatsheets</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../index.html" rel="" target="">
 <span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../list.html" rel="" target="">
 <span class="menu-text">List of Cheat Sheet</span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools ms-auto">
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#supervised-learning" id="toc-supervised-learning" class="nav-link active" data-scroll-target="#supervised-learning">Supervised Learning</a>
  <ul class="collapse">
  <li><a href="#supervised-vs.-unsupervised-learning" id="toc-supervised-vs.-unsupervised-learning" class="nav-link" data-scroll-target="#supervised-vs.-unsupervised-learning">Supervised vs.&nbsp;Unsupervised Learning</a></li>
  <li><a href="#common-terms" id="toc-common-terms" class="nav-link" data-scroll-target="#common-terms">Common terms</a>
  <ul class="collapse">
  <li><a href="#parameters-vs.-hyperparameters" id="toc-parameters-vs.-hyperparameters" class="nav-link" data-scroll-target="#parameters-vs.-hyperparameters">Parameters vs.&nbsp;Hyperparameters</a></li>
  </ul></li>
  <li><a href="#errors" id="toc-errors" class="nav-link" data-scroll-target="#errors">Errors</a></li>
  <li><a href="#training-validation-and-test-sets" id="toc-training-validation-and-test-sets" class="nav-link" data-scroll-target="#training-validation-and-test-sets">Training, Validation, and Test Sets</a>
  <ul class="collapse">
  <li><a href="#cross-validation" id="toc-cross-validation" class="nav-link" data-scroll-target="#cross-validation">Cross-Validation</a></li>
  </ul></li>
  <li><a href="#fundamental-trade-off" id="toc-fundamental-trade-off" class="nav-link" data-scroll-target="#fundamental-trade-off">Fundamental Trade-Off</a></li>
  <li><a href="#golden-rule-the-test-data-cannot-influence-the-training-phase-in-any-way." id="toc-golden-rule-the-test-data-cannot-influence-the-training-phase-in-any-way." class="nav-link" data-scroll-target="#golden-rule-the-test-data-cannot-influence-the-training-phase-in-any-way.">Golden Rule : THE TEST DATA CANNOT INFLUENCE THE TRAINING PHASE IN ANY WAY.</a></li>
  </ul></li>
  <li><a href="#types-of-supervised-learning" id="toc-types-of-supervised-learning" class="nav-link" data-scroll-target="#types-of-supervised-learning">Types of Supervised Learning</a>
  <ul class="collapse">
  <li><a href="#baseline" id="toc-baseline" class="nav-link" data-scroll-target="#baseline">Baseline</a></li>
  <li><a href="#decision-trees" id="toc-decision-trees" class="nav-link" data-scroll-target="#decision-trees">Decision Trees</a></li>
  <li><a href="#knn" id="toc-knn" class="nav-link" data-scroll-target="#knn">kNN</a></li>
  <li><a href="#svm-rbf" id="toc-svm-rbf" class="nav-link" data-scroll-target="#svm-rbf">SVM RBF</a></li>
  </ul></li>
  <li><a href="#preprocessing" id="toc-preprocessing" class="nav-link" data-scroll-target="#preprocessing">Preprocessing</a>
  <ul class="collapse">
  <li><a href="#scaling-values-using-standardscaler" id="toc-scaling-values-using-standardscaler" class="nav-link" data-scroll-target="#scaling-values-using-standardscaler">Scaling values using StandardScaler</a></li>
  <li><a href="#address-missing-values-using-simpleimputer" id="toc-address-missing-values-using-simpleimputer" class="nav-link" data-scroll-target="#address-missing-values-using-simpleimputer">Address missing values using SimpleImputer</a></li>
  <li><a href="#address-cataegorical-values-using-onehotencoder" id="toc-address-cataegorical-values-using-onehotencoder" class="nav-link" data-scroll-target="#address-cataegorical-values-using-onehotencoder">Address cataegorical values using OneHotEncoder</a>
  <ul class="collapse">
  <li><a href="#discretizing" id="toc-discretizing" class="nav-link" data-scroll-target="#discretizing">Discretizing</a></li>
  </ul></li>
  <li><a href="#address-catagorical-values-using-ordinalencoder" id="toc-address-catagorical-values-using-ordinalencoder" class="nav-link" data-scroll-target="#address-catagorical-values-using-ordinalencoder">Address catagorical values using OrdinalEncoder</a></li>
  <li><a href="#address-bag-of-words-using-countvectorizer" id="toc-address-bag-of-words-using-countvectorizer" class="nav-link" data-scroll-target="#address-bag-of-words-using-countvectorizer">Address Bag of Words using CountVectorizer</a></li>
  <li><a href="#sklearn-summary" id="toc-sklearn-summary" class="nav-link" data-scroll-target="#sklearn-summary">sklearn summary</a></li>
  <li><a href="#pipeline" id="toc-pipeline" class="nav-link" data-scroll-target="#pipeline">Pipeline</a></li>
  <li><a href="#column-transformer" id="toc-column-transformer" class="nav-link" data-scroll-target="#column-transformer">Column Transformer</a></li>
  <li><a href="#preprocessing-1" id="toc-preprocessing-1" class="nav-link" data-scroll-target="#preprocessing-1">Preprocessing</a>
  <ul class="collapse">
  <li><a href="#scaling-values-using-standardscaler-1" id="toc-scaling-values-using-standardscaler-1" class="nav-link" data-scroll-target="#scaling-values-using-standardscaler-1">Scaling values using StandardScaler</a></li>
  <li><a href="#address-missing-values-using-simpleimputer-1" id="toc-address-missing-values-using-simpleimputer-1" class="nav-link" data-scroll-target="#address-missing-values-using-simpleimputer-1">Address missing values using SimpleImputer</a></li>
  <li><a href="#address-cataegorical-values-using-onehotencoder-1" id="toc-address-cataegorical-values-using-onehotencoder-1" class="nav-link" data-scroll-target="#address-cataegorical-values-using-onehotencoder-1">Address cataegorical values using OneHotEncoder</a></li>
  </ul></li>
  <li><a href="#address-catagorical-values-using-ordinalencoder-1" id="toc-address-catagorical-values-using-ordinalencoder-1" class="nav-link" data-scroll-target="#address-catagorical-values-using-ordinalencoder-1">Address catagorical values using OrdinalEncoder</a>
  <ul class="collapse">
  <li><a href="#address-bag-of-words-using-countvectorizer-1" id="toc-address-bag-of-words-using-countvectorizer-1" class="nav-link" data-scroll-target="#address-bag-of-words-using-countvectorizer-1">Address Bag of Words using CountVectorizer</a></li>
  <li><a href="#sklearn-summary-1" id="toc-sklearn-summary-1" class="nav-link" data-scroll-target="#sklearn-summary-1">sklearn summary</a></li>
  <li><a href="#pipeline-1" id="toc-pipeline-1" class="nav-link" data-scroll-target="#pipeline-1">Pipeline</a></li>
  <li><a href="#column-transformer-1" id="toc-column-transformer-1" class="nav-link" data-scroll-target="#column-transformer-1">Column Transformer</a></li>
  </ul></li>
  <li><a href="#hyperparamter-optimization" id="toc-hyperparamter-optimization" class="nav-link" data-scroll-target="#hyperparamter-optimization">Hyperparamter Optimization</a>
  <ul class="collapse">
  <li><a href="#methods" id="toc-methods" class="nav-link" data-scroll-target="#methods">Methods</a></li>
  <li><a href="#grid-search" id="toc-grid-search" class="nav-link" data-scroll-target="#grid-search">Grid Search</a></li>
  <li><a href="#random-search" id="toc-random-search" class="nav-link" data-scroll-target="#random-search">Random Search</a></li>
  <li><a href="#random-vs-grid-search" id="toc-random-vs-grid-search" class="nav-link" data-scroll-target="#random-vs-grid-search">Random vs Grid Search</a></li>
  </ul></li>
  <li><a href="#naive-bayes" id="toc-naive-bayes" class="nav-link" data-scroll-target="#naive-bayes">Naive Bayes</a>
  <ul class="collapse">
  <li><a href="#bayes-theorem" id="toc-bayes-theorem" class="nav-link" data-scroll-target="#bayes-theorem">Bayes’ Theorem</a></li>
  <li><a href="#basic-idea" id="toc-basic-idea" class="nav-link" data-scroll-target="#basic-idea">Basic idea</a></li>
  <li><a href="#naive-bayes-1" id="toc-naive-bayes-1" class="nav-link" data-scroll-target="#naive-bayes-1">Naive Bayes</a></li>
  <li><a href="#laplace-smoothing" id="toc-laplace-smoothing" class="nav-link" data-scroll-target="#laplace-smoothing">Laplace Smoothing</a></li>
  <li><a href="#sklearn-implementation" id="toc-sklearn-implementation" class="nav-link" data-scroll-target="#sklearn-implementation">Sklearn Implementation</a></li>
  <li><a href="#continuous-features" id="toc-continuous-features" class="nav-link" data-scroll-target="#continuous-features">Continuous Features</a></li>
  </ul></li>
  <li><a href="#linear-models" id="toc-linear-models" class="nav-link" data-scroll-target="#linear-models">Linear Models</a>
  <ul class="collapse">
  <li><a href="#linear-regression" id="toc-linear-regression" class="nav-link" data-scroll-target="#linear-regression">Linear Regression</a></li>
  <li><a href="#logistic-regression" id="toc-logistic-regression" class="nav-link" data-scroll-target="#logistic-regression">Logistic Regression</a></li>
  <li><a href="#linear-svm" id="toc-linear-svm" class="nav-link" data-scroll-target="#linear-svm">Linear SVM</a></li>
  </ul></li>
  <li><a href="#multi-class-meta-strategies" id="toc-multi-class-meta-strategies" class="nav-link" data-scroll-target="#multi-class-meta-strategies">Multi-class, meta-strategies</a>
  <ul class="collapse">
  <li><a href="#one-vs-rest-ovr" id="toc-one-vs-rest-ovr" class="nav-link" data-scroll-target="#one-vs-rest-ovr">One-vs-Rest (OVR)</a></li>
  <li><a href="#one-vs-one-ovo" id="toc-one-vs-one-ovo" class="nav-link" data-scroll-target="#one-vs-one-ovo">One-vs-One (OVO)</a></li>
  <li><a href="#using-this-in-python" id="toc-using-this-in-python" class="nav-link" data-scroll-target="#using-this-in-python">Using this in Python</a></li>
  </ul></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">



<section id="supervised-learning" class="level1">
<h1>Supervised Learning</h1>
<ul>
<li><strong>Machine Learning</strong>: A field of study that gives computers the ability to learn without being explicitly programmed.
<ul>
<li>auto detect patterns in data and make predictions</li>
<li>Popular def of supervised learning: input: data + labels, output: model
<ul>
<li>Training a model from input data and its corresponding targets to predict targets for new examples.</li>
</ul></li>
</ul></li>
<li><strong>Fundamental goal of machine learning</strong>: generalize beyond the examples in the training set.</li>
</ul>
<section id="supervised-vs.-unsupervised-learning" class="level2">
<h2 class="anchored" data-anchor-id="supervised-vs.-unsupervised-learning">Supervised vs.&nbsp;Unsupervised Learning</h2>
<table class="table">
<colgroup>
<col style="width: 3%">
<col style="width: 53%">
<col style="width: 43%">
</colgroup>
<thead>
<tr class="header">
<th></th>
<th><strong>Supervised Learning</strong></th>
<th><strong>Unsupervised Learning</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Description</strong></td>
<td>The training data includes the desired solutions, called <strong>labels</strong>.</td>
<td>The training data is unlabeled.</td>
</tr>
<tr class="even">
<td><strong>Subtypes/Goals</strong></td>
<td>- Predict based on input data and its corresponding targets<br>- <strong>Classification</strong>: Predict a class label <br>e.g.&nbsp;will someone pass or fail final based on previous scores<br>- <strong>Regression</strong>: Predict a continuous number <br>e.g.&nbsp;what score will someone get on final based on previous score</td>
<td>- <strong>Clustering</strong>: Group similar instances<br>- <strong>Anomaly detection</strong>: Detect abnormal instances<br>- <strong>Visualization and dimensionality reduction</strong>: Simplify data<br>- <strong>Association rule learning</strong>: Discover relations between attributes</td>
</tr>
<tr class="odd">
<td><strong>Other Examples</strong></td>
<td>Decision tree, naive bayes, kNN, random forest, support vector machine, neural network</td>
<td>k-means, hierarchical cluster analysis, expectation maximization, t-SNE, apriori, FP-growth</td>
</tr>
</tbody>
</table>
</section>
<section id="common-terms" class="level2">
<h2 class="anchored" data-anchor-id="common-terms">Common terms</h2>
<ul>
<li><strong>Features/ X</strong>[n x d]: The input variables used to make predictions. (d = # of features)</li>
<li><strong>Target/ y</strong> [n x 1]: The output variable we are trying to predict.</li>
<li><strong>Example</strong>: A particular instance of data, usually represented as a vector of features. (n = # of training examples)</li>
<li><strong>Training</strong>: Fitting the model to examples.</li>
<li><strong>Label</strong>: The target value for a particular example. (y)</li>
</ul>
<section id="parameters-vs.-hyperparameters" class="level3">
<h3 class="anchored" data-anchor-id="parameters-vs.-hyperparameters">Parameters vs.&nbsp;Hyperparameters</h3>
<table class="table">
<colgroup>
<col style="width: 13%">
<col style="width: 34%">
<col style="width: 52%">
</colgroup>
<thead>
<tr class="header">
<th></th>
<th><strong>Parameters</strong></th>
<th><strong>Hyperparameters</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Description</strong></td>
<td>The coefficients learned by the model during training.</td>
<td>Settings used to control the training process.</td>
</tr>
<tr class="even">
<td><strong>Learning/Setting Process</strong></td>
<td>Are learned automatically during training.</td>
<td>Are set <strong>before</strong> training.</td>
</tr>
<tr class="odd">
<td><strong>Purpose or Role</strong></td>
<td>Rule values that are learned from the training data (examples/features).</td>
<td>Controls how complex the model is. Validate using validation score (can overfit if too complex).</td>
</tr>
<tr class="even">
<td><strong>Examples</strong></td>
<td>e.g.&nbsp;coefficients in linear regression, weights in neural networks</td>
<td>e.g.&nbsp;learning rate, number of iterations, number of hidden layers, depth of decision tree, k in kNN and k-means</td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="errors" class="level2">
<h2 class="anchored" data-anchor-id="errors">Errors</h2>
<ul>
<li>Generally there are 2 kinds of error:
<ol type="1">
<li><strong>Training error (<span class="math inline">\(E_{train}\)</span>)</strong>: Error on the training data.</li>
<li><strong>Distribution error/ test error/ generalization error (<span class="math inline">\(E_{D}\)</span>)</strong>: Error on new data.</li>
</ol></li>
<li><span class="math inline">\(E\_{approx} = E_{D} - E_{train}\)</span></li>
</ul>
</section>
<section id="training-validation-and-test-sets" class="level2">
<h2 class="anchored" data-anchor-id="training-validation-and-test-sets">Training, Validation, and Test Sets</h2>
<ul>
<li><strong>Training set</strong>: The data used to train the model. Used <em>a lot</em> to set parameters.</li>
<li><strong>Validation set</strong>: The data used to evaluate the model during training. Used <em>a few times</em> to set hyperparameters.</li>
<li><strong>Test set</strong>: The data used to evaluate the model after training. Used <em>once</em> to estimate <span class="math inline">\(E_{D}\)</span>.</li>
<li><strong>Deployment</strong>: The model is used in the real world.</li>
</ul>
<div class="sourceCode" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Used directly on X and y</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>    X, y, test_size<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span><span class="dv">123</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>)  <span class="co"># 80%-20% train test split on X and y</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Used on a dataframe</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>train_df, test_df <span class="op">=</span> train_test_split(</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>    df, test_size<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span><span class="dv">123</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>)  <span class="co"># 80%-20% train test split on df</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<section id="cross-validation" class="level3">
<h3 class="anchored" data-anchor-id="cross-validation">Cross-Validation</h3>
<ul>
<li>A method of estimating <span class="math inline">\(E_{D}\)</span> using the training set.
<ul>
<li>Divide the training set into <span class="math inline">\(k\)</span> folds.</li>
<li>For each fold, train on the other <span class="math inline">\(k-1\)</span> folds and evaluate on the current fold.</li>
</ul></li>
<li>Benefits:
<ul>
<li>More accurate estimate of <span class="math inline">\(E_{D}\)</span>. Sometimes just unlucky with train/test split, this helps.</li>
<li>More efficient use of data.</li>
</ul></li>
</ul>
<div class="sourceCode" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> cross_val_score, cross_validate</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="co"># cross_val_score not as comprehensive as cross_validate</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="co"># cross_val_score only returns the scores</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>cv_scores <span class="op">=</span> cross_val_score(model, X_train, y_train, cv<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="co"># using cross_validate</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>scores <span class="op">=</span> cross_validate(model, X_train, y_train, cv<span class="op">=</span><span class="dv">10</span>, return_train_score<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a><span class="co"># returns a dictionary with keys: ['fit_time', 'score_time', 'test_score', 'train_score']</span></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>pd.DataFrame(scores)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><em>cross-validation <strong>does not</strong> return a model. It is not a way to build a model that can be applied to new data. The purpose of cross-validation is to evaluate how well the model will generalize to unseen data.</em></p>
</section>
</section>
<section id="fundamental-trade-off" class="level2">
<h2 class="anchored" data-anchor-id="fundamental-trade-off">Fundamental Trade-Off</h2>
<ul>
<li>AKA the bias/ variance trade-off in supervised learning.
<ul>
<li><strong>Bias</strong>: Tendency to consistently learn the same wrong thing (high bias = underfitting).</li>
<li><strong>Variance</strong>: Tenency to learn random things irrespective of the real signal (high variance = overfitting).</li>
</ul></li>
<li>As you increase model complexity, <span class="math inline">\(E_{train}\)</span> goes down but <span class="math inline">\(E_{approx} = E_{D} - E_{train}\)</span> goes up. <img src="img/2_fto-1.png" width="250"> <img src="img/2_fto-2.png" width="250"></li>
</ul>
</section>
<section id="golden-rule-the-test-data-cannot-influence-the-training-phase-in-any-way." class="level2">
<h2 class="anchored" data-anchor-id="golden-rule-the-test-data-cannot-influence-the-training-phase-in-any-way.">Golden Rule : THE TEST DATA CANNOT INFLUENCE THE TRAINING PHASE IN ANY WAY.</h2>
</section>
</section>
<section id="types-of-supervised-learning" class="level1">
<h1>Types of Supervised Learning</h1>
<section id="baseline" class="level2">
<h2 class="anchored" data-anchor-id="baseline">Baseline</h2>
<ul>
<li><p>A simple, fast, and easily explainable model that is used as a starting point for a more sophisticated model.</p>
<ul>
<li>Most common baseline for classification is <strong>majority class classifier</strong>.</li>
<li>Most common baseline for regression is <strong>mean predictor</strong>.</li>
<li>in sklearn, <code>DummyClassifier</code> and <code>DummyRegressor</code> are used to create baselines.</li>
</ul></li>
</ul>
</section>
<section id="decision-trees" class="level2">
<h2 class="anchored" data-anchor-id="decision-trees">Decision Trees</h2>
<ul>
<li>basic idea: predict using a series of if-then-else questions</li>
<li>depth of tree: number of questions asked (hyperparameter)</li>
<li>decision boundary: region of feature space where all instances are assigned to the same class</li>
<li><strong>decision stump</strong>: a decision tree with only one split (depth = 1)</li>
</ul>
<table class="table">
<colgroup>
<col style="width: 33%">
<col style="width: 66%">
</colgroup>
<thead>
<tr class="header">
<th><strong>Advantages</strong></th>
<th><strong>Disadvantages</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>- Easy to interpret and explain.</td>
<td>- Biased with imbalanced datasets.</td>
</tr>
<tr class="even">
<td>- Can handle both numerical and categorical data.</td>
<td>- Greedy splitting algorithm might not find the globally optimal tree.</td>
</tr>
<tr class="odd">
<td>- Can handle multi-output problems.</td>
<td>- Hard to learn the true relationship between features and target (can only ask yes/no questions).</td>
</tr>
</tbody>
</table>
<div class="sourceCode" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.tree <span class="im">import</span> DecisionTreeClassifier</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> DecisionTreeClassifier(max_depth<span class="op">=</span><span class="dv">3</span>)  <span class="co"># create model object</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>clf.fit(X_train, y_train)  <span class="co"># fit model on training data</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>clf.score(X_test, y_test)  <span class="co"># score model on test data or use clf.predict(X_test)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<ul>
<li>can also use <code>DecisionTreeRegressor</code> for regression problems (continuous target)
<ul>
<li>difference:
<ul>
<li>score: returns R^2 score (1 is best, 0 is worst)</li>
<li>leaf nodes: returns average of target values in leaf node</li>
<li><code>DecisionTreeClassifier</code> uses entropy and <code>DecisionTreeRegressor</code> uses variance</li>
</ul></li>
</ul></li>
</ul>
</section>
<section id="knn" class="level2">
<h2 class="anchored" data-anchor-id="knn">kNN</h2>
<ul>
<li>kNN is a non-parametric model (no parameters to learn and stores all training data)</li>
<li>kNN is a lazy learner (no training, just prediction)
<ul>
<li>slow at prediction time</li>
</ul></li>
<li>kNN is a supervised model (needs labels)</li>
<li>hyperparameters:
<ul>
<li>k: number of neighbors to consider, smaller k means more complex decision boundary</li>
</ul></li>
</ul>
<div class="sourceCode" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.neighbors <span class="im">import</span> KNeighborsClassifier</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>knn <span class="op">=</span> KNeighborsClassifier(n_neighbors<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>knn.fit(X_train, y_train)</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>knn.score(X_test, y_test)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<table class="table">
<colgroup>
<col style="width: 43%">
<col style="width: 56%">
</colgroup>
<thead>
<tr class="header">
<th>Pros of k-NNs for Supervised Learning</th>
<th>Cons of k-NNs for Supervised Learning</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Easy to understand, interpret.</td>
<td>Can be potentially VERY slow during prediction time with a large training set.</td>
</tr>
<tr class="even">
<td>Simple hyperparameter (n_neighbors) controlling the tradeoff</td>
<td>Often not great test accuracy compared to modern approaches.</td>
</tr>
<tr class="odd">
<td>Can learn very complex functions given enough data.</td>
<td>Doesn’t work well on datasets with many features or sparse datasets.</td>
</tr>
<tr class="even">
<td>Lazy learning: Takes no time to fit</td>
<td>Falls apart when # dimensions increase (curse of dimensionality)</td>
</tr>
</tbody>
</table>
</section>
<section id="svm-rbf" class="level2">
<h2 class="anchored" data-anchor-id="svm-rbf">SVM RBF</h2>
<ul>
<li>SVM is a parametric model (needs to learn parameters)
<ul>
<li>remembers the support vectors</li>
<li>uses a kernel function to transform the data (RBF, Radial Basis Func, is the default)</li>
</ul></li>
<li>Decision boundary only depends on support vectors (smooth)</li>
<li>hyperparameters:
<ul>
<li>C: regularization parameter, larger C means more complex</li>
<li>gamma: kernel coefficient, larger gamma means more complex</li>
</ul></li>
</ul>
<div class="sourceCode" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.svm <span class="im">import</span> SVC</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>svm <span class="op">=</span> SVC(C<span class="op">=</span><span class="dv">10</span>, gamma<span class="op">=</span><span class="fl">0.1</span>)</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>svm.fit(X_train, y_train)</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>svm.score(X_test, y_test)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
</section>
<section id="preprocessing" class="level1">
<h1>Preprocessing</h1>
<section id="scaling-values-using-standardscaler" class="level2">
<h2 class="anchored" data-anchor-id="scaling-values-using-standardscaler">Scaling values using StandardScaler</h2>
<ul>
<li>in KNN, we need to scale the data (in classification, we don’t need to scale the data)</li>
</ul>
<div class="sourceCode" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>scaler <span class="op">=</span> StandardScaler()  <span class="co"># create feature trasformer object</span></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>scaler.fit(X_train)  <span class="co"># fitting the transformer on the train split</span></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>X_train_scaled <span class="op">=</span> scaler.transform(X_train)  <span class="co"># transforming the train split</span></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>X_test_scaled <span class="op">=</span> scaler.transform(X_test)  <span class="co"># transforming the test split</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="address-missing-values-using-simpleimputer" class="level2">
<h2 class="anchored" data-anchor-id="address-missing-values-using-simpleimputer">Address missing values using SimpleImputer</h2>
<ul>
<li>replace all missing values with the mean/ median of the column</li>
</ul>
<div class="sourceCode" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.impute <span class="im">import</span> SimpleImputer</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>imputer <span class="op">=</span> SimpleImputer(strategy<span class="op">=</span><span class="st">'median'</span>)  <span class="co"># create imputer object</span></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>imputer.fit(X_train_num_only)  <span class="co"># fitting the imputer on the train split</span></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>X_train_num_only_imputed <span class="op">=</span> imputer.transform(X_train_num_only)  <span class="co"># transforming the train split</span></span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>X_test_num_only_imputed <span class="op">=</span> imputer.transform(X_test_num_only)  <span class="co"># transforming the test split</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="address-cataegorical-values-using-onehotencoder" class="level2">
<h2 class="anchored" data-anchor-id="address-cataegorical-values-using-onehotencoder">Address cataegorical values using OneHotEncoder</h2>
<ul>
<li>turn categorical values into one-hot encoding</li>
<li>to get the column names, use <code>get_feature_names()</code>: <code>encoder.get_feature_names().tolist()</code></li>
</ul>
<div class="sourceCode" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> OneHotEncoder</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>encoder <span class="op">=</span> OneHotEncoder(handle_unknown<span class="op">=</span><span class="st">'ignore'</span>)  <span class="co"># create encoder object</span></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>encoder.fit(X_train_cat_only)  <span class="co"># fitting the encoder on the train split</span></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>X_train_cat_only_encoded <span class="op">=</span> encoder.transform(X_train_cat_only)  <span class="co"># transforming the train split</span></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>X_test_cat_only_encoded <span class="op">=</span> encoder.transform(X_test_cat_only)  <span class="co"># transforming the test split</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<ul>
<li>other arguments for OneHotEncoder:
<ul>
<li><code>handle_unknown='ignore'</code> will ignore unknown categories
<ul>
<li>if you don’t set this, you will get an error if there are unknown categories in the test set</li>
</ul></li>
<li><code>sparse_output=False</code> will return a dense matrix instead of a sparse matrix
<ul>
<li>default is <code>sparse_output=True</code> (returns a sparse matrix - only stores non-zero values)</li>
</ul></li>
<li><code>drop="if_binary"</code> will drop one of the columns if there are only two categories
<ul>
<li>default is <code>drop=None</code> (no columns are dropped)</li>
<li><code>drop="first"</code> will drop the first column</li>
<li><code>drop=[0, 2]</code> will drop the first and third columns</li>
</ul></li>
</ul></li>
</ul>
<section id="discretizing" class="level3">
<h3 class="anchored" data-anchor-id="discretizing">Discretizing</h3>
<ul>
<li>e.g turning age into age groups (e.g.&nbsp;child, adult, senior or 0-20, 20-40, 40-60, 60+)</li>
</ul>
</section>
</section>
<section id="address-catagorical-values-using-ordinalencoder" class="level2">
<h2 class="anchored" data-anchor-id="address-catagorical-values-using-ordinalencoder">Address catagorical values using OrdinalEncoder</h2>
<ul>
<li>turn categorical values into ordinal encoding (e.g.&nbsp;low, medium, high)</li>
<li><code>dtype=int</code> will make the output an integer</li>
</ul>
<div class="sourceCode" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> OrdinalEncoder</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>ordered_categories <span class="op">=</span> [<span class="st">'low'</span>, <span class="st">'medium'</span>, <span class="st">'high'</span>]</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>encoder <span class="op">=</span> OrdinalEncoder(categories<span class="op">=</span>[ordered_categories], dtype<span class="op">=</span><span class="bu">int</span>)  <span class="co"># create encoder object</span></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>encoder.fit(X_train_cat_only)  <span class="co"># fitting the encoder on the train split</span></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>X_train_cat_only_encoded <span class="op">=</span> encoder.transform(X_train_cat_only)  <span class="co"># transforming the train split</span></span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>X_test_cat_only_encoded <span class="op">=</span> encoder.transform(X_test_cat_only)  <span class="co"># transforming the test split</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="address-bag-of-words-using-countvectorizer" class="level2">
<h2 class="anchored" data-anchor-id="address-bag-of-words-using-countvectorizer">Address Bag of Words using CountVectorizer</h2>
<ul>
<li>turn a string of words into a vector of word counts (e.g., “white couch” -&gt; [“white”: 1, “couch”: 1])</li>
</ul>
<div class="sourceCode" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.feature_extraction.text <span class="im">import</span> CountVectorizer</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>vectorizer <span class="op">=</span> CountVectorizer(stop_words<span class="op">=</span><span class="st">'english'</span>)  <span class="co"># create vectorizer object</span></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>X_train_text_only_vectorized <span class="op">=</span> vectorizer.fit_transform(X_train_text_only)  <span class="co"># fitting and transforming the train split</span></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>X_test_text_only_vectorized <span class="op">=</span> vectorizer.transform(X_test_text_only)  <span class="co"># transforming the test split</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<ul>
<li>Parameters:
<ul>
<li><code>stop_words='english'</code> will remove common English words (e.g., “the”, “a”, “an”, “and”, “or”, “but”, “not”)
<ul>
<li>default is <code>stop_words=None</code> (no words are removed)</li>
</ul></li>
<li><code>max_features=100</code> will only keep the 100 most common words
<ul>
<li>default is <code>max_features=None</code> (all words are kept)</li>
</ul></li>
</ul></li>
<li>handles unknown words by ignoring them</li>
</ul>
</section>
<section id="sklearn-summary" class="level2">
<h2 class="anchored" data-anchor-id="sklearn-summary">sklearn summary</h2>
<table class="table">
<colgroup>
<col style="width: 16%">
<col style="width: 38%">
<col style="width: 44%">
</colgroup>
<thead>
<tr class="header">
<th></th>
<th><strong>Estimators</strong></th>
<th><strong>Transformers</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Purpose</strong></td>
<td>used to fit and predict</td>
<td>used to change input data</td>
</tr>
<tr class="even">
<td><strong>Usage</strong></td>
<td>Need to fit X_train, y_train</td>
<td>Need to fit X_train (no y_train)</td>
</tr>
<tr class="odd">
<td></td>
<td>Can score on X_test, y_test</td>
<td>nothing to score</td>
</tr>
<tr class="even">
<td><strong>Examples</strong></td>
<td>- DecisionTreeClassifier</td>
<td>- StandardScaler</td>
</tr>
<tr class="odd">
<td></td>
<td>- KNeighborsClassifier</td>
<td>- SimpleImputer</td>
</tr>
<tr class="even">
<td></td>
<td>- LogisticRegression</td>
<td>- OneHotEncoder</td>
</tr>
<tr class="odd">
<td></td>
<td>- SVC</td>
<td>- OrdinalEncoder</td>
</tr>
</tbody>
</table>
<ul>
<li>Don’t fit with transformer then cross validate with estimator
<ul>
<li>This is data leakage (train is influenced by validation)</li>
</ul></li>
<li>solution: Use Sklearn Pipeline!</li>
</ul>
</section>
<section id="pipeline" class="level2">
<h2 class="anchored" data-anchor-id="pipeline">Pipeline</h2>
<ul>
<li>use sklearn.pipeline.Pipeline</li>
<li>make a pipeline:</li>
</ul>
<div class="sourceCode" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.pipeline <span class="im">import</span> make_pipeline</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>pipe_knn <span class="op">=</span> make_pipeline(</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>    SimpleImputer(strategy<span class="op">=</span><span class="st">'median'</span>),</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>    StandardScaler(),</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>    KNeighborsClassifier(n_neighbors<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="column-transformer" class="level2">
<h2 class="anchored" data-anchor-id="column-transformer">Column Transformer</h2>
<ul>
<li>This is a transformer that can handle multiple columns</li>
</ul>
<div class="sourceCode" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.compose <span class="im">import</span> make_column_transformer</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>preprocessor <span class="op">=</span> make_column_transformer(</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>    (make_pipeline(SimpleImputer(), StandardScaler()), numeric_feats),  <span class="co"># scaling on numeric features</span></span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>    (<span class="st">"passthrough"</span>, passthrough_feats),  <span class="co"># no transformations on the binary features</span></span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>    (OneHotEncoder(), categorical_feats),  <span class="co"># OHE on categorical features</span></span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>    <span class="co"># normally OHE is put at the end since it makes new cols</span></span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>    (<span class="st">"drop"</span>, drop_feats),  <span class="co"># drop the drop features</span></span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<ul>
<li>get names of transformers: <code>preprocessor.named_transformers_</code></li>
<li>get new column names: <code>preprocessor.named_transformers_["onehotencoder"].get_feature_names()</code></li>
</ul>
</section>
<section id="preprocessing-1" class="level2">
<h2 class="anchored" data-anchor-id="preprocessing-1">Preprocessing</h2>
<section id="scaling-values-using-standardscaler-1" class="level3">
<h3 class="anchored" data-anchor-id="scaling-values-using-standardscaler-1">Scaling values using StandardScaler</h3>
<ul>
<li>in KNN, we need to scale the data (in classification, we don’t need to scale the data)</li>
</ul>
<div class="sourceCode" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>scaler <span class="op">=</span> StandardScaler()  <span class="co"># create feature trasformer object</span></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>scaler.fit(X_train)  <span class="co"># fitting the transformer on the train split</span></span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>X_train_scaled <span class="op">=</span> scaler.transform(X_train)  <span class="co"># transforming the train split</span></span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>X_test_scaled <span class="op">=</span> scaler.transform(X_test)  <span class="co"># transforming the test split</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="address-missing-values-using-simpleimputer-1" class="level3">
<h3 class="anchored" data-anchor-id="address-missing-values-using-simpleimputer-1">Address missing values using SimpleImputer</h3>
<ul>
<li>replace all missing values with the mean/ median of the column</li>
</ul>
<div class="sourceCode" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.impute <span class="im">import</span> SimpleImputer</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>imputer <span class="op">=</span> SimpleImputer(strategy<span class="op">=</span><span class="st">'median'</span>)  <span class="co"># create imputer object</span></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>imputer.fit(X_train_num_only)  <span class="co"># fitting the imputer on the train split</span></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>X_train_num_only_imputed <span class="op">=</span> imputer.transform(X_train_num_only)  <span class="co"># transforming the train split</span></span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>X_test_num_only_imputed <span class="op">=</span> imputer.transform(X_test_num_only)  <span class="co"># transforming the test split</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="address-cataegorical-values-using-onehotencoder-1" class="level3">
<h3 class="anchored" data-anchor-id="address-cataegorical-values-using-onehotencoder-1">Address cataegorical values using OneHotEncoder</h3>
<ul>
<li>turn categorical values into one-hot encoding</li>
<li>to get the column names, use <code>get_feature_names()</code>: <code>encoder.get_feature_names().tolist()</code></li>
</ul>
<div class="sourceCode" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> OneHotEncoder</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>encoder <span class="op">=</span> OneHotEncoder(handle_unknown<span class="op">=</span><span class="st">'ignore'</span>)  <span class="co"># create encoder object</span></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>encoder.fit(X_train_cat_only)  <span class="co"># fitting the encoder on the train split</span></span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>X_train_cat_only_encoded <span class="op">=</span> encoder.transform(X_train_cat_only)  <span class="co"># transforming the train split</span></span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>X_test_cat_only_encoded <span class="op">=</span> encoder.transform(X_test_cat_only)  <span class="co"># transforming the test split</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<ul>
<li>other arguments for OneHotEncoder:
<ul>
<li><code>handle_unknown='ignore'</code> will ignore unknown categories
<ul>
<li>if you don’t set this, you will get an error if there are unknown categories in the test set</li>
</ul></li>
<li><code>sparse_output=False</code> will return a dense matrix instead of a sparse matrix
<ul>
<li>default is <code>sparse_output=True</code> (returns a sparse matrix - only stores non-zero values)</li>
</ul></li>
<li><code>drop="if_binary"</code> will drop one of the columns if there are only two categories
<ul>
<li>default is <code>drop=None</code> (no columns are dropped)</li>
<li><code>drop="first"</code> will drop the first column</li>
<li><code>drop=[0, 2]</code> will drop the first and third columns</li>
</ul></li>
</ul></li>
</ul>
<section id="discretizing-1" class="level4">
<h4 class="anchored" data-anchor-id="discretizing-1">Discretizing</h4>
<ul>
<li>e.g turning age into age groups (e.g.&nbsp;child, adult, senior or 0-20, 20-40, 40-60, 60+)</li>
</ul>
</section>
</section>
</section>
<section id="address-catagorical-values-using-ordinalencoder-1" class="level2">
<h2 class="anchored" data-anchor-id="address-catagorical-values-using-ordinalencoder-1">Address catagorical values using OrdinalEncoder</h2>
<ul>
<li>turn categorical values into ordinal encoding (e.g.&nbsp;low, medium, high)</li>
<li><code>dtype=int</code> will make the output an integer</li>
</ul>
<div class="sourceCode" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> OrdinalEncoder</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>ordered_categories <span class="op">=</span> [<span class="st">'low'</span>, <span class="st">'medium'</span>, <span class="st">'high'</span>]</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>encoder <span class="op">=</span> OrdinalEncoder(categories<span class="op">=</span>[ordered_categories], dtype<span class="op">=</span><span class="bu">int</span>)  <span class="co"># create encoder object</span></span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>encoder.fit(X_train_cat_only)  <span class="co"># fitting the encoder on the train split</span></span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>X_train_cat_only_encoded <span class="op">=</span> encoder.transform(X_train_cat_only)  <span class="co"># transforming the train split</span></span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>X_test_cat_only_encoded <span class="op">=</span> encoder.transform(X_test_cat_only)  <span class="co"># transforming the test split</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<section id="address-bag-of-words-using-countvectorizer-1" class="level3">
<h3 class="anchored" data-anchor-id="address-bag-of-words-using-countvectorizer-1">Address Bag of Words using CountVectorizer</h3>
<ul>
<li>turn a string of words into a vector of word counts (e.g., “white couch” -&gt; [“white”: 1, “couch”: 1])</li>
</ul>
<div class="sourceCode" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.feature_extraction.text <span class="im">import</span> CountVectorizer</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>vectorizer <span class="op">=</span> CountVectorizer(stop_words<span class="op">=</span><span class="st">'english'</span>)  <span class="co"># create vectorizer object</span></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>X_train_text_only_vectorized <span class="op">=</span> vectorizer.fit_transform(X_train_text_only)  <span class="co"># fitting and transforming the train split</span></span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>X_test_text_only_vectorized <span class="op">=</span> vectorizer.transform(X_test_text_only)  <span class="co"># transforming the test split</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<ul>
<li>Parameters:
<ul>
<li><code>stop_words='english'</code> will remove common English words (e.g., “the”, “a”, “an”, “and”, “or”, “but”, “not”)
<ul>
<li>default is <code>stop_words=None</code> (no words are removed)</li>
</ul></li>
<li><code>max_features=100</code> will only keep the 100 most common words
<ul>
<li>default is <code>max_features=None</code> (all words are kept)</li>
</ul></li>
<li><code>binary=True</code> will only keep 0 or 1 for each word (instead of the count)
<ul>
<li>default is <code>binary=False</code> (the count is kept)</li>
</ul></li>
</ul></li>
<li>handles unknown words by ignoring them</li>
</ul>
<section id="breaking-golden-rule" class="level4">
<h4 class="anchored" data-anchor-id="breaking-golden-rule">Breaking Golden Rule</h4>
<ul>
<li>If we know fixed categories (i.e., provinces in Canada), we can break the golden rule and pass the list of known/possible categories</li>
</ul>
</section>
</section>
<section id="sklearn-summary-1" class="level3">
<h3 class="anchored" data-anchor-id="sklearn-summary-1">sklearn summary</h3>
<table class="table">
<colgroup>
<col style="width: 16%">
<col style="width: 38%">
<col style="width: 44%">
</colgroup>
<thead>
<tr class="header">
<th></th>
<th><strong>Estimators</strong></th>
<th><strong>Transformers</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Purpose</strong></td>
<td>used to fit and predict</td>
<td>used to change input data</td>
</tr>
<tr class="even">
<td><strong>Usage</strong></td>
<td>Need to fit X_train, y_train</td>
<td>Need to fit X_train (no y_train)</td>
</tr>
<tr class="odd">
<td></td>
<td>Can score on X_test, y_test</td>
<td>nothing to score</td>
</tr>
<tr class="even">
<td><strong>Examples</strong></td>
<td>- DecisionTreeClassifier</td>
<td>- StandardScaler</td>
</tr>
<tr class="odd">
<td></td>
<td>- KNeighborsClassifier</td>
<td>- SimpleImputer</td>
</tr>
<tr class="even">
<td></td>
<td>- LogisticRegression</td>
<td>- OneHotEncoder</td>
</tr>
<tr class="odd">
<td></td>
<td>- SVC</td>
<td>- OrdinalEncoder</td>
</tr>
</tbody>
</table>
<ul>
<li>Don’t fit with transformer then cross validate with estimator
<ul>
<li>This is data leakage (train is influenced by validation)</li>
</ul></li>
<li>solution: Use Sklearn Pipeline!</li>
</ul>
</section>
<section id="pipeline-1" class="level3">
<h3 class="anchored" data-anchor-id="pipeline-1">Pipeline</h3>
<ul>
<li>use sklearn.pipeline.Pipeline</li>
<li>make a pipeline:</li>
</ul>
<div class="sourceCode" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.pipeline <span class="im">import</span> make_pipeline</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>pipe_knn <span class="op">=</span> make_pipeline(</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>    SimpleImputer(strategy<span class="op">=</span><span class="st">'median'</span>),</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>    StandardScaler(),</span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>    KNeighborsClassifier(n_neighbors<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a>scores <span class="op">=</span> cross_validate(pipe_knn, X_train, y_train, return_train_score<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a>pipe_knn.fit(X_train, y_train)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="column-transformer-1" class="level3">
<h3 class="anchored" data-anchor-id="column-transformer-1">Column Transformer</h3>
<ul>
<li>This is a transformer that can handle multiple columns</li>
</ul>
<div class="sourceCode" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.compose <span class="im">import</span> make_column_transformer</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>preprocessor <span class="op">=</span> make_column_transformer(</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>    (make_pipeline(SimpleImputer(), StandardScaler()), numeric_feats),  <span class="co"># scaling on numeric features</span></span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>    (<span class="st">"passthrough"</span>, passthrough_feats),  <span class="co"># no transformations on the binary features</span></span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>    (OneHotEncoder(), categorical_feats),  <span class="co"># OHE on categorical features</span></span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a>    <span class="co"># normally OHE is put at the end since it makes new cols</span></span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a>    (<span class="st">"drop"</span>, drop_feats),  <span class="co"># drop the drop features</span></span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<ul>
<li>get names of transformers: <code>preprocessor.named_transformers_</code></li>
<li>get new column names: <code>preprocessor.named_transformers_["onehotencoder"].get_feature_names()</code></li>
</ul>
</section>
</section>
<section id="hyperparamter-optimization" class="level2">
<h2 class="anchored" data-anchor-id="hyperparamter-optimization">Hyperparamter Optimization</h2>
<section id="methods" class="level3">
<h3 class="anchored" data-anchor-id="methods">Methods</h3>
<ul>
<li>Manual
<ul>
<li>Takes a lot of time</li>
<li>intuition is not always correct</li>
<li>some hyperparameters work together</li>
</ul></li>
<li>Automated
<ul>
<li>Grid search</li>
</ul></li>
</ul>
</section>
<section id="grid-search" class="level3">
<h3 class="anchored" data-anchor-id="grid-search">Grid Search</h3>
<ul>
<li><strong>Exhaustive</strong> search over specified parameter values for an estimator
<ul>
<li>runs <span class="math inline">\(n^m\)</span> CV for m hyperparameters and n values for each parameter</li>
</ul></li>
<li>After finding best parameter, it trains/fits the model on the whole training set</li>
</ul>
<section id="parameters" class="level4">
<h4 class="anchored" data-anchor-id="parameters">Parameters:</h4>
<ul>
<li><code>GridSearchCV(estimator, param_grid, scoring=None, cv=None, n_jobs=None))</code></li>
<li><strong>estimator</strong>: estimator object</li>
<li><strong>param_grid</strong>: dictionary with parameters names as keys and lists of parameter settings to try as values
<ul>
<li>uses <code>__</code> syntax to specify parameters of the estimator</li>
<li>e.g:
<ul>
<li><code>columntransformer__countvectorizer__max_features</code>: max features of count vectorizer in column transformer</li>
<li><code>svc__gamma</code>: gamma of SVC</li>
</ul></li>
</ul></li>
<li><strong>scoring</strong>: scoring method</li>
<li><strong>cv</strong>: cross-validation method</li>
<li><strong>n_jobs</strong>: number of jobs to run in parallel (-1 means use all processors)</li>
</ul>
</section>
<section id="code" class="level4">
<h4 class="anchored" data-anchor-id="code">Code</h4>
<div class="sourceCode" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> GridSearchCV</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>pipe_svm <span class="op">=</span> make_pipeline(preprocessor, SVC())</span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>param_grid <span class="op">=</span> {</span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">"columntransformer__countvectorizer__max_features"</span>: [<span class="dv">100</span>, <span class="dv">200</span>, <span class="dv">400</span>, <span class="dv">800</span>, <span class="dv">1000</span>, <span class="dv">2000</span>],</span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a>    <span class="st">"svc__gamma"</span>: [<span class="fl">0.001</span>, <span class="fl">0.01</span>, <span class="fl">0.1</span>, <span class="fl">1.0</span>, <span class="dv">10</span>, <span class="dv">100</span>],</span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a>    <span class="st">"svc__C"</span>: [<span class="fl">0.001</span>, <span class="fl">0.01</span>, <span class="fl">0.1</span>, <span class="fl">1.0</span>, <span class="dv">10</span>, <span class="dv">100</span>],</span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a grid search object</span></span>
<span id="cb20-12"><a href="#cb20-12" aria-hidden="true" tabindex="-1"></a>gs <span class="op">=</span> GridSearchCV(pipe_svm, param_grid<span class="op">=</span>param_grid, cv<span class="op">=</span><span class="dv">5</span>, n_jobs<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb20-13"><a href="#cb20-13" aria-hidden="true" tabindex="-1"></a>gs.fit(X_train, y_train)</span>
<span id="cb20-14"><a href="#cb20-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-15"><a href="#cb20-15" aria-hidden="true" tabindex="-1"></a>gs.best_score_ <span class="co"># returns the best score</span></span>
<span id="cb20-16"><a href="#cb20-16" aria-hidden="true" tabindex="-1"></a>gs.best_params_ <span class="co"># returns the best parameters</span></span>
<span id="cb20-17"><a href="#cb20-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Returns a dataframe of all the results</span></span>
<span id="cb20-18"><a href="#cb20-18" aria-hidden="true" tabindex="-1"></a>pd.DataFrame(random_search.cv_results_)[</span>
<span id="cb20-19"><a href="#cb20-19" aria-hidden="true" tabindex="-1"></a>    [</span>
<span id="cb20-20"><a href="#cb20-20" aria-hidden="true" tabindex="-1"></a>        <span class="st">"mean_test_score"</span>,</span>
<span id="cb20-21"><a href="#cb20-21" aria-hidden="true" tabindex="-1"></a>        <span class="st">"param_columntransformer__countvectorizer__max_features"</span>,</span>
<span id="cb20-22"><a href="#cb20-22" aria-hidden="true" tabindex="-1"></a>        <span class="st">"param_svc__gamma"</span>,</span>
<span id="cb20-23"><a href="#cb20-23" aria-hidden="true" tabindex="-1"></a>        <span class="st">"param_svc__C"</span>,</span>
<span id="cb20-24"><a href="#cb20-24" aria-hidden="true" tabindex="-1"></a>        <span class="st">"mean_fit_time"</span>,</span>
<span id="cb20-25"><a href="#cb20-25" aria-hidden="true" tabindex="-1"></a>        <span class="st">"rank_test_score"</span>,</span>
<span id="cb20-26"><a href="#cb20-26" aria-hidden="true" tabindex="-1"></a>    ]</span>
<span id="cb20-27"><a href="#cb20-27" aria-hidden="true" tabindex="-1"></a>].set_index(<span class="st">"rank_test_score"</span>).sort_index().T</span>
<span id="cb20-28"><a href="#cb20-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-29"><a href="#cb20-29" aria-hidden="true" tabindex="-1"></a><span class="co"># Can score on the test set</span></span>
<span id="cb20-30"><a href="#cb20-30" aria-hidden="true" tabindex="-1"></a>gs.score(X_test, y_test)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
</section>
<section id="random-search" class="level3">
<h3 class="anchored" data-anchor-id="random-search">Random Search</h3>
<ul>
<li>Picks random values for the hyperparameters according to a distribution</li>
<li>only runs n_iter CV</li>
</ul>
<section id="parameters-1" class="level4">
<h4 class="anchored" data-anchor-id="parameters-1">Parameters</h4>
<ul>
<li><code>RandomizedSearchCV(estimator, param_distributions, n_iter=10, scoring=None, cv=None, n_jobs=None))</code></li>
<li><strong>estimator</strong>: estimator object</li>
<li><strong>param_distributions</strong>: dictionary with parameters names as keys and distributions or lists of parameters to try
<ul>
<li>can also pass param_grid from grid search (but does not exhaustively search)</li>
</ul></li>
<li><strong>n_iter</strong>: number of parameter settings that are sampled</li>
<li><strong>scoring</strong>: scoring method</li>
<li><strong>cv</strong>: cross-validation method</li>
<li><strong>n_jobs</strong>: number of jobs to run in parallel (-1 means use all processors)</li>
</ul>
</section>
<section id="code-1" class="level4">
<h4 class="anchored" data-anchor-id="code-1">Code</h4>
<div class="sourceCode" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> RandomizedSearchCV</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>param_dist <span class="op">=</span> {</span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">"columntransformer__countvectorizer__max_features"</span>: randint(<span class="dv">100</span>, <span class="dv">2000</span>),</span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">"svc__C"</span>: uniform(<span class="fl">0.1</span>, <span class="fl">1e4</span>),  <span class="co"># loguniform(1e-3, 1e3),</span></span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">"svc__gamma"</span>: loguniform(<span class="fl">1e-5</span>, <span class="fl">1e3</span>),</span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a>rs <span class="op">=</span> RandomizedSearchCV(</span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a>    pipe_svm,</span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a>    param_distributions<span class="op">=</span>param_dist,</span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a>    n_iter<span class="op">=</span><span class="dv">10</span>,</span>
<span id="cb21-13"><a href="#cb21-13" aria-hidden="true" tabindex="-1"></a>    cv<span class="op">=</span><span class="dv">5</span>,</span>
<span id="cb21-14"><a href="#cb21-14" aria-hidden="true" tabindex="-1"></a>    n_jobs<span class="op">=-</span><span class="dv">1</span>,</span>
<span id="cb21-15"><a href="#cb21-15" aria-hidden="true" tabindex="-1"></a>    random_state<span class="op">=</span><span class="dv">42</span>,</span>
<span id="cb21-16"><a href="#cb21-16" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
</section>
<section id="random-vs-grid-search" class="level3">
<h3 class="anchored" data-anchor-id="random-vs-grid-search">Random vs Grid Search</h3>
<ul>
<li>Advantages of Random Search
<ul>
<li>Faster</li>
<li>Adding hyperparameters that do not influence the performance does not decrease the performance</li>
<li>Works better when some hyperparameters are more important than others</li>
<li>recommended more than grid search</li>
</ul></li>
</ul>
</section>
</section>
<section id="naive-bayes" class="level2">
<h2 class="anchored" data-anchor-id="naive-bayes">Naive Bayes</h2>
<section id="bayes-theorem" class="level3">
<h3 class="anchored" data-anchor-id="bayes-theorem">Bayes’ Theorem</h3>
<p><span class="math display">\[ P(A|B) = \frac{P(B|A)P(A)}{P(B)} \]</span></p>
</section>
<section id="basic-idea" class="level3">
<h3 class="anchored" data-anchor-id="basic-idea">Basic idea</h3>
<ul>
<li>We have a set of classes (e.g.&nbsp;spam or not spam)</li>
<li>We have a set of features (e.g.&nbsp;words in an email)</li>
</ul>
<p>We want to find the probability of a class given a set of features.</p>
<p><span class="math display">\[ P(C|F_1, F_2, ..., F_n) = \frac{P(F_1, F_2, ..., F_n|C)P(C)}{P(F_1, F_2, ..., F_n)} \]</span></p>
</section>
<section id="naive-bayes-1" class="level3">
<h3 class="anchored" data-anchor-id="naive-bayes-1">Naive Bayes</h3>
<ul>
<li><strong>Bag of words model</strong> (order of words doesn’t matter)</li>
<li>Assume that all features are <strong>conditionally independent</strong> of each other (naive assumption)</li>
<li>This allows us to simplify the equation to:</li>
</ul>
<p><span class="math display">\[ P(C|F*1, F_2, ..., F_n) \approx \frac{P(C)* \prod P(F_i|C)}{P(F_1, F_2, ..., F_n)} \]</span></p>
</section>
<section id="laplace-smoothing" class="level3">
<h3 class="anchored" data-anchor-id="laplace-smoothing">Laplace Smoothing</h3>
<ul>
<li>If a word is not in the training set, then the probability of that word given a class is 0</li>
<li>This will cause the entire probability to be 0</li>
<li>We can fix this by adding 1 to the numerator and adding the number of words to the denominator</li>
</ul>
<p><span class="math display">\[ P(F_i|C) = \frac{count(F_i, C) + 1}{count(C) + |V|} \]</span></p>
<p>where V is the number of possible word values</p>
</section>
<section id="sklearn-implementation" class="level3">
<h3 class="anchored" data-anchor-id="sklearn-implementation">Sklearn Implementation</h3>
<div class="sourceCode" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.naive_bayes <span class="im">import</span> MultinomialNB, BernoulliNB</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>pipe_nb <span class="op">=</span> make_pipeline(CountVectorizer(), MultinomialNB())</span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a>results_dict[<span class="st">"Naive Bayes"</span>] <span class="op">=</span> mean_std_cross_val_scores(</span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a>    pipe_nb, X_train, y_train, return_train_score<span class="op">=</span><span class="va">True</span></span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<ul>
<li>MultinomialNB generally works better than BernoulliNB, especially for large text datasets
<ul>
<li>BernoulliNB assumes that the features are binary (e.g.&nbsp;0 or 1)</li>
<li>MultinomialNB assumes that the features are counts (e.g.&nbsp;0, 1, 2, 3, …)</li>
</ul></li>
<li>Parameters:
<ul>
<li><code>alpha</code> is the Laplace smoothing parameter (actually hyperparameter), default is <code>alpha=1.0</code>
<ul>
<li>High alpha means more smoothing =&gt; underfitting</li>
<li>Low alpha means less smoothing =&gt; overfitting</li>
</ul></li>
</ul></li>
</ul>
</section>
<section id="continuous-features" class="level3">
<h3 class="anchored" data-anchor-id="continuous-features">Continuous Features</h3>
<ul>
<li>We can use a Gaussian Naive Bayes model for continuous features</li>
<li>This assumes that the features are normally distributed
<ul>
<li>If not, can use <code>sklearn.preprocessing.PowerTransformer</code> to transform the data to be more normal</li>
</ul></li>
</ul>
<div class="sourceCode" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.naive_bayes <span class="im">import</span> GaussianNB</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> GaussianNB()</span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>model.fit(X_train, y_train)</span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a><span class="co"># view</span></span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a>model.theta_  <span class="co"># mean of each feature per class</span></span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a>model.sigma_  <span class="co"># variance of each feature per class</span></span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a>model.var_ <span class="co"># overall variance of each feature</span></span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a>model.class_prior_  <span class="co"># prior probability of each class</span></span>
<span id="cb23-11"><a href="#cb23-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-12"><a href="#cb23-12" aria-hidden="true" tabindex="-1"></a>model.predict_proba(X_test)  <span class="co"># probability of each class</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
</section>
<section id="linear-models" class="level2">
<h2 class="anchored" data-anchor-id="linear-models">Linear Models</h2>
<ul>
<li>make predictions using a linear function of the input features</li>
<li>decision boundary is a hyperplane
<ul>
<li>if 2d, decision boundary is a line</li>
<li>uncertain near the decision boundary</li>
</ul></li>
<li>Limitations:
<ul>
<li>can only learn linear decision boundaries</li>
<li>can only learn linear functions of the input features</li>
</ul></li>
</ul>
<section id="linear-regression" class="level3">
<h3 class="anchored" data-anchor-id="linear-regression">Linear Regression</h3>
<ul>
<li>Main idea: find the line that minimizes the sum of squared errors</li>
<li><strong>Components</strong>:
<ul>
<li>input features (d features)</li>
<li>coefficients (d coefficients)</li>
<li>intercept/ bias (1 intercept)</li>
</ul></li>
<li>Normally has <code>d+1</code> parameters (one for each feature plus the intercept)</li>
<li>Makes <code>d-1</code> hyperplanes (separating lines) in <code>d</code> dimensions</li>
<li>More complex normally means the coefficients are larger</li>
<li>Raw output score can be used to calculate probability score for a given prediction</li>
<li>SCALING IS IMPORTANT
<ul>
<li>If features are on different scales, the coefficients will be on different scales</li>
</ul></li>
</ul>
<section id="ridge" class="level4">
<h4 class="anchored" data-anchor-id="ridge">Ridge</h4>
<p><span class="math display">\[ \min\_{w} ||Xw - y||\_2^2 + \alpha ||w||\_2^2 \]</span></p>
<ul>
<li>L2 regularization</li>
<li>Hyperparameters:
<ul>
<li><code>alpha</code>: regularization strength
<ul>
<li>larger values =&gt; more regularization =&gt; simpler model =&gt; underfitting</li>
<li>more regularization =&gt; smaller coefficients =&gt; less sensitive to changes in input features (outliers)</li>
</ul></li>
</ul></li>
</ul>
<div class="sourceCode" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> Ridge</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>pipe <span class="op">=</span> make_pipeline(StandardScaler(), Ridge())</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>scores <span class="op">=</span> cross_validate(pipe, X_train, y_train, return_train_score<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a>coeffs <span class="op">=</span> pipe_ridge.named_steps[<span class="st">"ridge"</span>].coef_ <span class="co"># view coefficients</span></span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a><span class="co"># coeffs.shape = (n_features,), one coefficient for each feature</span></span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a>intercept <span class="op">=</span> pipe_ridge.named_steps[<span class="st">"ridge"</span>].intercept_ <span class="co"># view intercept/ bias</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="laso" class="level4">
<h4 class="anchored" data-anchor-id="laso">Laso</h4>
<p><span class="math display">\[ \min\_{w} ||Xw - y||\_2^2 + \alpha ||w||\_1 \]</span></p>
<ul>
<li>L1 regularization</li>
<li>Hyperparameters:
<ul>
<li><code>alpha</code>: regularization strength
<ul>
<li>larger values =&gt; more regularization =&gt; simpler model =&gt; underfitting</li>
</ul></li>
</ul></li>
</ul>
</section>
</section>
<section id="logistic-regression" class="level3">
<h3 class="anchored" data-anchor-id="logistic-regression">Logistic Regression</h3>
<ul>
<li>Main idea: use linear regression to predict the probability of an event</li>
<li>Applies a “threshold” to the raw output score to make a prediction -&gt; decides whether to predict 0/1 or -1/1</li>
<li><strong>Components</strong>:
<ul>
<li>input features (d features)</li>
<li>coefficients (d coefficients)</li>
<li>intercept/ bias (1 intercept)</li>
<li>threshold r (1 threshold)</li>
</ul></li>
<li>Hyperparameters:
<ul>
<li><code>C</code>: inverse of regularization strength
<ul>
<li>larger values =&gt; less regularization =&gt; more complex model =&gt; overfitting</li>
</ul></li>
</ul></li>
</ul>
<div class="sourceCode" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LogisticRegression</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>lr <span class="op">=</span> LogisticRegression()</span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>scores <span class="op">=</span> cross_validate(lr, X_train, y_train, return_train_score<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a><span class="co"># access coefficients and intercept</span></span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a>lr.coef_ <span class="co"># shape = (n_classes, n_features)</span></span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a>lr.intercept_ <span class="co"># shape = (n_classes,)</span></span>
<span id="cb25-9"><a href="#cb25-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-10"><a href="#cb25-10" aria-hidden="true" tabindex="-1"></a>lr.classes_ <span class="co"># array of classes</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<ul>
<li><code>predict_proba</code> returns the probability of each class
<ul>
<li>for binary classification, returns both classes (although one is redundant)</li>
<li>based on the order of <code>lr.classes_</code></li>
<li>sum of probabilities for each sample is 1</li>
</ul></li>
<li><code>predict</code> returns the class with the highest probability</li>
</ul>
<section id="sigmoid-function" class="level4">
<h4 class="anchored" data-anchor-id="sigmoid-function">sigmoid function</h4>
<p><span class="math display">\[ \sigma(z) = \frac{1}{1 + e^{-z}} \]</span></p>
<ul>
<li>turns -inf to 0 and inf to 1 <img src="img/8_sigmoid.png" width="250"></li>
</ul>
</section>
</section>
<section id="linear-svm" class="level3">
<h3 class="anchored" data-anchor-id="linear-svm">Linear SVM</h3>
<ul>
<li>Main idea: find the line that maximizes the margin between the decision boundary and the closest points</li>
</ul>
<div class="sourceCode" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.svm <span class="im">import</span> SVC</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>linear_svc <span class="op">=</span> SVC(kernel<span class="op">=</span><span class="st">"linear"</span>)</span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a>scores <span class="op">=</span> cross_validate(linear_svc, X_train, y_train, return_train_score<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
</section>
<section id="multi-class-meta-strategies" class="level2">
<h2 class="anchored" data-anchor-id="multi-class-meta-strategies">Multi-class, meta-strategies</h2>
<ul>
<li>Can do multiclass naturally: KNN, decision trees</li>
<li>2 hacky ways to use binary classifiers for multi-class classification:</li>
</ul>
<section id="one-vs-rest-ovr" class="level3">
<h3 class="anchored" data-anchor-id="one-vs-rest-ovr">One-vs-Rest (OVR)</h3>
<ul>
<li>Train a binary classifier for each class
<ul>
<li>creates binary linear classifiers separating each class from the rest (i.e blue vs rest, red vs rest, green vs rest)</li>
</ul></li>
<li>Classify by choosing the class with the highest probability</li>
</ul>
<p><img src="img/8_one_rest.png" width="400"></p>
<p>e.g.&nbsp;a point on (0, -5) would get:</p>
<ul>
<li><code>lr.coef_</code> would give 3x2 array (3 classes, 2 features)</li>
<li><code>lr.intercept_</code> would give 3x1 array (3 classes, 1 intercept)</li>
<li>Get score with <code>test_points[4]@lr.coef_.T + lr.intercept_</code> return array size 3, choose the class with the highest score</li>
</ul>
</section>
<section id="one-vs-one-ovo" class="level3">
<h3 class="anchored" data-anchor-id="one-vs-one-ovo">One-vs-One (OVO)</h3>
<ul>
<li>Train a binary classifier for each pair of classes
<ul>
<li>creates binary linear classifiers separating each class from each other class (i.e blue vs red, blue vs green, red vs green)</li>
<li>trains <span class="math inline">\(\frac{n(n-1)}{2}\)</span> classifiers</li>
</ul></li>
<li>count the number of times each class wins</li>
<li>Classify by choosing the class with the most wins</li>
</ul>
</section>
<section id="using-this-in-python" class="level3">
<h3 class="anchored" data-anchor-id="using-this-in-python">Using this in Python</h3>
<div class="sourceCode" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.multiclass <span class="im">import</span> OneVsOneClassifier, OneVsRestClassifier</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> OneVsOneClassifier(LogisticRegression())</span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>timeit model.fit(X_train_multi, y_train_multi)<span class="op">;</span></span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> OneVsRestClassifier(LogisticRegression())</span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>timeit model.fit(X_train_multi, y_train_multi)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>


</section>
</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>